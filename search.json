[
  {
    "objectID": "sessions/comparative_metagenomics.html",
    "href": "sessions/comparative_metagenomics.html",
    "title": "Comparative metagenomics",
    "section": "",
    "text": "In this practical session, we aim to demonstrate how the MGnifyR tool can be used to fetch data and metadata of a MGnify metagenomic analysis. Then we show diversity metrics calculus and two methods to identify differentially abundant features using taxonomic and functional profiles generated through the MGnify v5.0 pipeline for metagenomic assemblies, as shown in the workflow schema below.\nThe dataset is the TARA ocean metagenomic study (WMS) corresponding to size fractions for prokaryotes MGYS00002008. Find more information about the TARA Ocean Project.\n\nimage: https://www.ebi.ac.uk/metagenomics/static/5e55649e459d5f26ee6c.png alt: Alt Text width: 800px caption: Mgnify assembly analysis pipeline v5.0\n\nMGnifyR is a library that provides a set of tools for easily accessing and processing MGnify data in R, making queries to MGnify databases through the MGnify API. The benefits of MGnifyR are that data can either be fetched in TSV format or be directly combined in a phyloseq object to run an analysis in a custom workflow.\nThe exercises are organized into 5 main sections:\n\nFetching data and preprocessing\nNormalization, alpha diversity indices and taxonomic profiles visualization\nComparative metagenomics at community level: Beta diversity\nDetection of differentially abundant taxa (SIAMCAT)\nDetection of differentially abundant functions (Aldex2)"
  },
  {
    "objectID": "sessions/comparative_metagenomics.html#normalization-methods-alpha-beta-diversity-and-differentially-abundant-features",
    "href": "sessions/comparative_metagenomics.html#normalization-methods-alpha-beta-diversity-and-differentially-abundant-features",
    "title": "Comparative metagenomics",
    "section": "",
    "text": "In this practical session, we aim to demonstrate how the MGnifyR tool can be used to fetch data and metadata of a MGnify metagenomic analysis. Then we show diversity metrics calculus and two methods to identify differentially abundant features using taxonomic and functional profiles generated through the MGnify v5.0 pipeline for metagenomic assemblies, as shown in the workflow schema below.\nThe dataset is the TARA ocean metagenomic study (WMS) corresponding to size fractions for prokaryotes MGYS00002008. Find more information about the TARA Ocean Project.\n\nimage: https://www.ebi.ac.uk/metagenomics/static/5e55649e459d5f26ee6c.png alt: Alt Text width: 800px caption: Mgnify assembly analysis pipeline v5.0\n\nMGnifyR is a library that provides a set of tools for easily accessing and processing MGnify data in R, making queries to MGnify databases through the MGnify API. The benefits of MGnifyR are that data can either be fetched in TSV format or be directly combined in a phyloseq object to run an analysis in a custom workflow.\nThe exercises are organized into 5 main sections:\n\nFetching data and preprocessing\nNormalization, alpha diversity indices and taxonomic profiles visualization\nComparative metagenomics at community level: Beta diversity\nDetection of differentially abundant taxa (SIAMCAT)\nDetection of differentially abundant functions (Aldex2)"
  },
  {
    "objectID": "sessions/comparative_metagenomics.html#open-the-jupyther-notebook",
    "href": "sessions/comparative_metagenomics.html#open-the-jupyther-notebook",
    "title": "Comparative metagenomics",
    "section": "Open the Jupyther Notebook",
    "text": "Open the Jupyther Notebook\nThe practice has been prepared in a Jupyter Notebook available in the MGnify Notebooks Github repo.\n\n\n\n\n\n\nTo access the notebook open a terminal and run the following commands:\n\n\n\ncd ~/mgnify-notebooks\ntask edit-notebooks\n\n\n\n\n\n\n\n\nFind and open the ‘comparative_practice_2023’ notebook in the ‘R examples’ directory\n\n\n\n\n\n\n\n\n\n\n\n\nThe notebook has colored boxes to indicate relevant steps in the analysis or to introduce material for discussion\n\n\n\nYellow boxes: * Up to you: To re-run the analysis changing parameters * Questions: For open discussion\nBlue boxes: * Notes: Informative boxes about the running command * Tips: Information useful for results interpretation\n\n\n\n\n\n\n\n\nTo leave the notebook, you can save the changes and close the window in the browser. Then, terminate the process at the terminal:\n\n\n\nCTRL+C"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Metagenomics bioinformatics at MGnify (2023)",
    "section": "",
    "text": "This is a draft\n\n\n\nThese notes are being written currently. The content will change and be expanded upon in the lead up to the course.\n\n\nThis is the course material for the Metagenomics bioinformatics at MGnify course (2023).\n\nOverview\nGain knowledge of the tools, processes and analysis approaches used in the field of metagenomics.\nThis course will cover the metagenomics data analysis workflow from the point of newly generated sequence data. Participants will explore the use of publicly available resources and tools to manage, share, analyse and interpret metagenomics data. The content will include issues of data quality control and how to submit to public repositories. While sessions will detail marker-gene and whole-genome shotgun (WGS) approaches; the primary focus will be on assembly-based approaches. Discussions will also explore considerations when assembling genome data, the analysis that can be carried out by MGnify on such datasets, and what downstream analysis options and tools are available"
  },
  {
    "objectID": "sessions/qc.html",
    "href": "sessions/qc.html",
    "title": "Quality control and filtering of the raw sequence files",
    "section": "",
    "text": "These instructions are for the course VM. To run externally, please refer to the section at the end.\nFor this tutorial, you’ll need to move into the working directory and start a Docker container. Set the variable DATADIR as instructed.\ncd /home/training/quality\nchmod -R 777 /home/training/quality\nexport DATADIR=/home/training/quality\nxhost +\nNow start the Docker container:\ndocker run --rm -it  -e DISPLAY=$DISPLAY  -v $DATADIR:/opt/data -v /tmp/.X11-unix:/tmp/.X11-unix:rw -e DISPLAY=unix$DISPLAY microbiomeinformatics/biata-qc-assembly:v2021"
  },
  {
    "objectID": "sessions/qc.html#prerequisites",
    "href": "sessions/qc.html#prerequisites",
    "title": "Quality control and filtering of the raw sequence files",
    "section": "",
    "text": "These instructions are for the course VM. To run externally, please refer to the section at the end.\nFor this tutorial, you’ll need to move into the working directory and start a Docker container. Set the variable DATADIR as instructed.\ncd /home/training/quality\nchmod -R 777 /home/training/quality\nexport DATADIR=/home/training/quality\nxhost +\nNow start the Docker container:\ndocker run --rm -it  -e DISPLAY=$DISPLAY  -v $DATADIR:/opt/data -v /tmp/.X11-unix:/tmp/.X11-unix:rw -e DISPLAY=unix$DISPLAY microbiomeinformatics/biata-qc-assembly:v2021"
  },
  {
    "objectID": "sessions/qc.html#quality-control-and-filtering-of-the-raw-sequence-files",
    "href": "sessions/qc.html#quality-control-and-filtering-of-the-raw-sequence-files",
    "title": "Quality control and filtering of the raw sequence files",
    "section": "Quality control and filtering of the raw sequence files",
    "text": "Quality control and filtering of the raw sequence files\n\n\n\n\n\n\nLearning Objectives\n\n\n\nIn the following exercises, you’ll learn how to check the quality of short read sequences, identify adaptor sequences, remove adapters and low-quality sequences, and construct a reference database for host decontamination.\n\n\n\n\n\n\n\n\nHere you should see the contents of the working directory.\n\n\n\nThese are the files we’ll use for the practical. Move into the folder:\nls /opt/data\ncd /opt/data\n\n\n\n\n\n\n\n\nGenerate a directory of the FastQC results\n\n\n\nmkdir fastqc_results\nfastqc oral_human_example_1_splitaa.fastq.gz\nfastqc oral_human_example_2_splitaa.fastq.gz\nmv *.zip fastqc_results\nmv *.html fastqc_results\n\n\n\n\n\n\n\n\nNow on your computer, select the folder icon.\n\n\n\nNavigate to Home → quality → fastqc_results\nRight-click on file oral_human_example_1_splitaa_fastqc.html, select ‘open with other application’, and open with Firefox.\n\n\n\nScreenshot of fast qc\n\n\nSpend some time looking at the ‘Per base sequence quality.’\n\n\nFor each position, a BoxWhisker-type plot is drawn:\n\nThe central red line is the median value.\nThe yellow box represents the inter-quartile range (25-75%).\nThe upper and lower whiskers represent the 10% and 90% points.\nThe blue line represents the mean quality.\n\nThe y-axis on the graph shows the quality scores. The higher the score, the better the base call. The background of the graph divides the y-axis into very good quality calls (green), calls of reasonable quality (orange), and calls of poor quality (red). The quality of calls on most platforms will degrade as the run progresses, so it’s common to see base calls falling into the orange area towards the end of a read.\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does this tell you about your sequence data? When do the errors start?\n\n\nIn the pre-processed files, we see two warnings, as shown on the left side of the report. Navigate to the “Per bases sequence content.”\n\n\n\nScreenshot of fast qc\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nAt around 15-19 nucleotides, the DNA composition becomes very even; however, at the 5’ end of the sequence, there are distinct differences. Why do you think that is?\n\n\n\n\n\n\n\n\nStep\n\n\n\nOpen up the FastQC report corresponding to the reversed reads.\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nAre there any significant differences between the forward and reverse files?\n\n\nFor more information on the FastQC report, please consult the ‘Documentation’ available from this site: FastQC Documentation\nWe are currently only looking at two files, but often we want to look at many files. The tool multiqc aggregates the FastQC results across many samples and creates a single report for easy comparison. Here we will demonstrate the use of this tool.\n\n\n\n\n\n\nRun\n\n\n\ncd /opt/data\nmkdir multiqc_results\nmultiqc fastqc_results -o multiqc_results\n\n\nIn this case, we provide the folder containing the FastQC results to multiqc, and the -o allows us to set the output directory for this summarized report.\n\n\n\n\n\n\nNow on your computer, select the folder icon.\n\n\n\nNavigate to Home → quality → multiqc_results\nRight-click on file multiqc_report.html, select ‘open with other application’, and open with Firefox.\n\n\n\nScreenshot of multiQC\n\n\nScroll down through the report. The sequence quality histograms show the above results from each file as two separate lines. The ‘Status Checks’ show a matrix of which samples passed check and which ones have problems.\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat fraction of reads are duplicates?\n\n\nSo far we have looked at the raw files and assessed their content, but we have not done anything about removing duplicates, sequences with low quality scores, or removal of the adaptors. So, let’s start this process. The first step in the process is to make a database relevant for decontaminating the sample. It is always good to routinely screen for human DNA (which may come from the host and/or staff performing the experiment). However, if the sample is from a mouse, you would want to download the mouse genome.\nIn the following exercise, we are going to use two “genomes” already downloaded for you in the decontamination folder. To make this tutorial quicker and smaller in terms of file sizes, we are going to use PhiX (a common spike in) and just chromosome 10 from human.\n\n\n\n\n\n\nRun\n\n\n\ncd /opt/data/decontamination\n\n\nFor the next step, we need one file, so we want to merge the two different fasta files. This is simply done using the command-line tool cat.\n\n\n\n\n\n\nRun\n\n\n\ncat phix.fasta GRCh38_chr10.fasta &gt; GRCh38_phix.fasta\n\n\nNow we need to build a bowtie index for them:\n\n\n\n\n\n\nRun\n\n\n\nbowtie2-build GRCh38_phix.fasta GRCh38_phix.index\n\n\nIt is possible to automatically download a pre-indexed human genome in Bowtie2 format using the following command (but do not do this now, as this will take a while to download):\n\nkneaddata_database –download human_genome bowtie2\n\nNow we are going to use the GRCh38_phix database and clean up our raw sequences. kneaddata is a helpful wrapper script for a number of pre-processing tools, including Bowtie2 to screen out contaminant sequences, and Trimmomatic to exclude low-quality sequences. We also have written wrapper scripts to run these tools (see below), but using kneaddata allows for more flexibility in options.\n\n\n\n\n\n\nRun\n\n\n\ncd /opt/data\nmkdir clean\n\n\nWe now need to uncompress the fastq files.\n\n\n\n\n\n\nCompress\n\n\n\ngunzip -c oral_human_example_2_splitaa.fastq.gz &gt; oral_human_example_2_splitaa.fastq\ngunzip -c oral_human_example_1_splitaa.fastq.gz &gt; oral_human_example_1_splitaa.fastq\n\nkneaddata --remove-intermediate-output -t 2 --input oral_human_example_1_splitaa.fastq --input oral_human_example_2_splitaa.fastq --output /opt/data/clean --reference-db /opt/data/decontamination/GRCh38_phix.index --bowtie2-options \"--very-sensitive --dovetail\" --trimmomatic /opt/data/Trimmomatic-0.39/ --bypass-trf --trimmomatic-options \"SLIDINGWINDOW:4:20 MINLEN:50\"\n\n\nThe options above are:\n\n--input, Input FASTQ file. This option is given twice as we have paired-end data.\n--output, Output directory.\n--reference-db, Path to Bowtie2 database for decontamination.\n-t, Number of threads to use (2 in this case).\n--trimmomatic-options, Options for Trimmomatic to use, in quotations.\n--bowtie2-options, Options for Bowtie2 to use, in quotations.\n--remove-intermediate-output, Intermediate files, including large FASTQs, will be removed.\n\nKneaddata generates multiple outputs in the “clean” directory, containing different four different files for each read.\n\n\n\n\n\n\nRun FastQC\n\n\n\nUsing what you have learned previously, generate a FastQC report for each of the oral_human_example_1_splitaa_kneaddata_paired files. Do this within the clean directory.\ncd /opt/data/clean\nmkdir fastqc_final\n&lt;you construct the commands&gt;\nmv /opt/data/clean/*.zip /opt/data/clean/fastqc_final\nmv /opt/data/clean/*.html /opt/data/clean/fastqc_final\n\n\n\n\n\n\n\n\nRun multiQC\n\n\n\nAlso generate a multiQC report and look at the sequence quality histograms.\ncd /opt/data/clean/\nmkdir multiqc_final\n&lt;you construct the command&gt;\n\n\n\n\n\n\n\n\nCheck report\n\n\n\nView the MultiQC report as before using your browser.\n\n\n\nScreenshot of multiQC\n\n\nScroll down through the report. The sequence quality histograms show the above results from each file as two separate lines. The ‘Status Checks’ show a matrix of which samples passed check and which ones have problems.\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nOpen the previous MultiQC report and see if they have improved?\nDid sequences at the 5’ end become uniform? Why might that be? Is there anything that suggests that adaptor sequences were found?\n\n\nTo generate a summary file of how the sequences were categorized by Kneaddata, run the following command.\n\n\n\n\n\n\nRun\n\n\n\ncd /opt/data/clean\nkneaddata_read_count_table --input /opt/data/clean --output kneaddata_read_counts.txt\ncat kneaddata_read_counts.txt\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat fraction of reads have been deemed to be contaminating?\n\n\nThe reads have now been decontaminated and can be uploaded to ENA, one of the INSDC members. It is beyond the scope of this course to include a tutorial on how to submit to ENA, but there is additional information available on how to do this in this Online Training guide provided by EMBL-EBI"
  },
  {
    "objectID": "sessions/qc.html#assembly-phix-decontamination",
    "href": "sessions/qc.html#assembly-phix-decontamination",
    "title": "Quality control and filtering of the raw sequence files",
    "section": "Assembly PhiX decontamination",
    "text": "Assembly PhiX decontamination\n\n\n\n\n\n\nLearning Objectives\n\n\n\nIn the following exercises, you will generate a PhiX blast database and run a blast search with a subset of assembled freshwater sediment metagenomic reads to identify contamination.\n\n\nPhiX, used in the previous section of this practical, is a small bacteriophage genome typically used as a calibration control in sequencing runs. Most library preparations will use PhiX at low concentrations; however, it can still appear in the sequencing run. If not filtered out, PhiX can form small spurious contigs that could be incorrectly classified as diversity.\n\n\n\n\n\n\nGenerate the PhiX reference blast database:\n\n\n\ncd /opt/data/decontamination\nmakeblastdb -in phix.fasta -input_type fasta -dbtype nucl -parse_seqids -out phix_blastDB\n\n\nPrepare the freshwater sediment example assembly file and search against the new blast database. This assembly file contains only a subset of the contigs for the purpose of this practical.\n\n\n\n\n\n\nRun\n\n\n\ncd /opt/data\ngunzip -c freshwater_sediment_contigs.fa.gz &gt; freshwater_sediment_contigs.fa\nblastn -query freshwater_sediment_contigs.fa -db decontamination/phix_blastDB -task megablast -word_size 28 -best_hit_overhang 0.1 -best_hit_score_edge 0.1 -dust yes -evalue 0.0001 -min_raw_gapped_score 100 -penalty -5 -soft_masking true -window_size 100 -outfmt 6 -out freshwater_blast_out.txt\n\n\nThe blast options are:\n\n-query, Input assembly fasta file.\n-out, Output file\n-db, Path to blast database.\n-task, Search type -“megablast”, for very similar sequences (e.g, sequencing errors)\n-word_size, Length of initial exact match\n\n\n\n\n\n\n\nAdd headers to the blast output and look at the contents of the final output file:\n\n\n\ncat blast_outfmt6.txt freshwater_blast_out.txt &gt; freshwater_blast_out_headers.txt\ncat freshwater_blast_out_headers.txt\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nAre the hits significant?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat are the lengths of the matching contigs? We would typically filter metagenomic contigs at a length of 500bp. Would any PhiX contamination remain after this filter?\n\n\nNow that PhiX contamination was identified, it is important to remove these contigs from the assembly file before further analysis or upload to public archives."
  },
  {
    "objectID": "sessions/qc.html#using-negative-controls",
    "href": "sessions/qc.html#using-negative-controls",
    "title": "Quality control and filtering of the raw sequence files",
    "section": "Using Negative Controls",
    "text": "Using Negative Controls\n\n\n\n\n\n\nLearning Objectives\n\n\n\nThis exercise will look at the analysis of negative controls. You will assess the microbial diversity between a negative control and a skin sample.\n\n\nThe images below show the taxonomic classification of two samples: a reagent negative control and a skin metagenomic sample. The skin sample is taken from the antecubital fossa - the elbow crease, which is moist and site of high microbial diversity. The classification was performed with kraken2. Kraken2 takes a while to run, so we have done this for you and plotted the results. An example of the command used to do this:\n\nkraken2 --db standard_db --threshold 0.10 --threads 8 --use-names --fastq-input --report out.report --gzip-compressed in_1.fastq.gz in_2.fastq.gz See the kraken2 manual for more information\n\nSee Pavian manual for the plots.\nThe following image shows the microbial abundance in the negative control: \nThe following image shows the microbial abundance in the skin sample: \n\n\n\n\n\n\nStep\n\n\n\nLook for similarities and differences at both the phylum and genus level - labelled as ‘P’ and ‘G’ on the bottom axis.\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nIs there any overlap between the negative control and skin sample phylum? Can we map the negative control directly to the skin sample to remove all contaminants? If not, why?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nAre there any genera in the negative control which aren’t present in the skin sample? If you do a google search of this genus, where are they commonly found? With this information, where could this bacteria in the negative control have originated from?\n\n\nIf you have finished the practical you can try this step for more practice assessing and trimming datasets, there is another set of raw reads called “skin_example_aa” from the skin metagenome available. These will require a fastqc or multiqc report, followed by trimming and mapping to the reference database with kneaddata. Using what you have learned previously, construct the relevant commands. Remember to check the quality before and after trimming.\n\n\n\n\n\n\nTip\n\n\n\nConsider other trimmomatic options from the manual e.g. “ILLUMINACLIP”, where /opt/data/NexteraPE-PE is a file of adapters.\n\n\n\n\n\n\n\n\nNavigate to skin folder and run quality control\n\n\n\ncd /opt/data/skin\n&lt;construct the required commands&gt;"
  }
]